{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd165a94-63f2-431e-bd89-0c1e0ea4f844",
   "metadata": {},
   "source": [
    "# Single Image Super-Resolution\n",
    "This is the primary training notebook for training models for all the loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cba8e2-4388-43d8-84c6-fb4768546a88",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7758c0d4-f8ce-4d89-8d03-25a45922d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import io, transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d0596b7-9e88-4517-b328-cd61aa972d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: torchsummary in /home/ec2-user/.local/lib/python3.7/site-packages (1.5.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: pytorch_msssim in /home/ec2-user/.local/lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib64/python3.7/site-packages (from pytorch_msssim) (1.13.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch->pytorch_msssim) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.7/site-packages (from torch->pytorch_msssim) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.7/site-packages (from torch->pytorch_msssim) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.7/site-packages (from torch->pytorch_msssim) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.7/site-packages (from torch->pytorch_msssim) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->pytorch_msssim) (60.8.2)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->pytorch_msssim) (0.37.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: torchmetrics in /home/ec2-user/.local/lib/python3.7/site-packages (0.11.4)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib64/python3.7/site-packages (from torchmetrics) (1.21.5)\n",
      "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib64/python3.7/site-packages (from torchmetrics) (1.13.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/site-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torchmetrics) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.7/site-packages (from torch>=1.8.1->torchmetrics) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.7/site-packages (from torch>=1.8.1->torchmetrics) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.7/site-packages (from torch>=1.8.1->torchmetrics) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.7/site-packages (from torch>=1.8.1->torchmetrics) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.1->torchmetrics) (60.8.2)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.1->torchmetrics) (0.37.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging->torchmetrics) (3.0.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "!pip install pytorch_msssim\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b8e79a9-2969-4201-8a2a-a93790dc37cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ec2-user/.local/lib/python3.7/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59b45b4a-a06d-498e-8bd7-3611e1b5febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_msssim import ssim\n",
    "from torchsummary import summary\n",
    "from torchmetrics.functional import structural_similarity_index_measure as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f55a156-422d-47dd-8c5c-5ecb63307251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cu117\n",
      "0.14.0+cu117\n",
      "Tesla T4\n",
      "_CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_properties(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f56628ed-0610-486c-b36f-bbcf4617eba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d4bac-7bd7-4b98-a0c4-21cd39ac5c79",
   "metadata": {},
   "source": [
    "## Data Pre-processing and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "246e2958-e23d-4274-8e0b-49f06e3f7563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paired data transformation for training including 0 degrees\n",
    "paired_transform = PairedTransform([\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomVerticalFlip(),\n",
    "    RandomRotationSpecific([0, 90, 180, 270])\n",
    "])\n",
    "\n",
    "tensor_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor with values between [0, 1]\n",
    "    # transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Initialize dataset\n",
    "batch_size = 16\n",
    "hr_dir = \"HR_patches\"\n",
    "# lr_x2_dir = \"LR_x2_patches\"\n",
    "lr_x4_dir = \"LR_x4_patches\"\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset = SRDataset(hr_dir, \n",
    "                    lr_x4_dir,\n",
    "                    paired_transform=paired_transform, \n",
    "                    tensor_transform=tensor_transform,\n",
    "                    paired_transform_prob=0.5)\n",
    "\n",
    "# Split the dataset into a smaller subset\n",
    "subset_size = int(0.35 * len(dataset))\n",
    "discard_size = len(dataset) - subset_size\n",
    "subset_dataset, _ = random_split(dataset, [subset_size, discard_size])\n",
    "\n",
    "# Second split: 90% for training, 10% for validation\n",
    "train_size = int(0.9 * len(subset_dataset))\n",
    "val_size = len(subset_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(subset_dataset, [train_size, val_size])\n",
    "\n",
    "# Create subsets for training and validation\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True, \n",
    "                          num_workers=4,\n",
    "                          pin_memory=True,\n",
    "                          collate_fn=custom_collate_fn)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=False, \n",
    "                        num_workers=4,\n",
    "                        pin_memory=True,\n",
    "                        collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "666efabb-5bcf-4573-8003-5fd2ca9edddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18900, 2100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f28ef3-9438-48b7-bdac-202832b362bb",
   "metadata": {},
   "source": [
    "## Defining Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b35c7a7-7191-453d-815d-2e979262295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Inception Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, batch_norm=False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels) if batch_norm else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        if self.bn1:\n",
    "            out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = out + residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# Defining Residual-in-Residual Block\n",
    "class ResidualInResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, batch_norm=False):\n",
    "        super(ResidualInResidualBlock, self).__init__()\n",
    "        self.res1 = ResidualBlock(in_channels, out_channels, batch_norm)\n",
    "        self.res2 = ResidualBlock(out_channels, out_channels, batch_norm)\n",
    "        # self.res3 = ResidualBlock(out_channels, out_channels, batch_norm)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.res1(x)\n",
    "        out = self.res2(out)\n",
    "        # out = self.res3(out)\n",
    "        return out + x\n",
    "\n",
    "# Defining the U-Net architecture\n",
    "class UNetSRx4RiR(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, num_features=64, dropout_rate=0.0):\n",
    "        super(UNetSRx4RiR, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(in_channels, num_features, kernel_size=3, padding=1)\n",
    "        self.encoder1 = ResidualInResidualBlock(num_features, num_features, batch_norm=True)\n",
    "        self.downsample1 = self.downsample(num_features, num_features * 2, dropout_rate)\n",
    "\n",
    "        self.encoder2 = ResidualInResidualBlock(num_features * 2, num_features * 2, batch_norm=True)\n",
    "        self.downsample2 = self.downsample(num_features * 2, num_features * 4, dropout_rate)\n",
    "\n",
    "        self.encoder3 = ResidualInResidualBlock(num_features * 4, num_features * 4, batch_norm=True)\n",
    "        self.downsample3 = self.downsample(num_features * 4, num_features * 8, dropout_rate)\n",
    "\n",
    "        self.encoder4 = ResidualInResidualBlock(num_features * 8, num_features * 8, batch_norm=True)\n",
    "        self.downsample4 = self.downsample(num_features * 8, num_features * 16, dropout_rate)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = ResidualInResidualBlock(num_features * 16, num_features * 16, batch_norm=True)\n",
    "\n",
    "        # Decoder\n",
    "        \n",
    "        self.upconv4 = nn.ConvTranspose2d(num_features * 16, num_features * 8, kernel_size=2, stride=2)\n",
    "        self.decoder4 = ResidualInResidualBlock(num_features * 16, num_features * 16, batch_norm=True)\n",
    "        self.conv3 = nn.Conv2d(num_features * 16, num_features * 8, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.upconv3 = nn.ConvTranspose2d(num_features * 8, num_features * 4, kernel_size=2, stride=2)\n",
    "        self.decoder3 = ResidualInResidualBlock(num_features * 8, num_features * 8, batch_norm=True)\n",
    "        self.conv4 = nn.Conv2d(num_features * 8, num_features * 4, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(num_features * 4, num_features * 2, kernel_size=2, stride=2)\n",
    "        self.decoder2 = ResidualInResidualBlock(num_features * 4, num_features * 4, batch_norm=True)\n",
    "        self.conv5 = nn.Conv2d(num_features * 4, num_features * 2, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv1 = nn.ConvTranspose2d(num_features * 2, num_features, kernel_size=2, stride=2)\n",
    "        self.decoder1 = ResidualInResidualBlock(num_features * 2, num_features * 2, batch_norm=True)\n",
    "\n",
    "        # Final output layer\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.Conv2d(num_features * 2, num_features, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(num_features, out_channels, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def downsample(self, in_channels, out_channels, dropout_rate, batch_norm=True):\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=2)]\n",
    "        if batch_norm:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "        layers.append(nn.ReLU())\n",
    "        if dropout_rate > 0:\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First upscale x4 using bicubic interpolation\n",
    "        x = torch.nn.functional.interpolate(x, scale_factor=4, mode='bicubic', align_corners=False)\n",
    "\n",
    "        # Encoder\n",
    "        enc1 = self.conv1(x) \n",
    "        enc1 = self.encoder1(enc1) \n",
    "\n",
    "        enc2 = self.downsample1(enc1) \n",
    "        enc2 = self.encoder2(enc2)\n",
    "\n",
    "        enc3 = self.downsample2(enc2)\n",
    "        enc3 = self.encoder3(enc3) \n",
    "\n",
    "        enc4 = self.downsample3(enc3)\n",
    "        enc4 = self.encoder4(enc4)\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = self.downsample4(enc4)\n",
    "        bottleneck = self.bottleneck(bottleneck)\n",
    "\n",
    "        # Decoder\n",
    "        dec4 = self.upconv4(bottleneck) \n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec4 = self.conv3(dec4)\n",
    "        \n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec3 = self.conv4(dec3)\n",
    "\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec2 = self.conv5(dec2)\n",
    "\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "\n",
    "        sr = self.final_conv(dec1)\n",
    "\n",
    "        return sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ce1fe97-95ca-4056-9233-55e3d41fa309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           1,792\n",
      "            Conv2d-2         [-1, 64, 256, 256]           4,096\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "            Conv2d-4         [-1, 64, 256, 256]          36,864\n",
      "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
      "              ReLU-6         [-1, 64, 256, 256]               0\n",
      "              ReLU-7         [-1, 64, 256, 256]               0\n",
      "     ResidualBlock-8         [-1, 64, 256, 256]               0\n",
      "            Conv2d-9         [-1, 64, 256, 256]           4,096\n",
      "             ReLU-10         [-1, 64, 256, 256]               0\n",
      "           Conv2d-11         [-1, 64, 256, 256]          36,864\n",
      "      BatchNorm2d-12         [-1, 64, 256, 256]             128\n",
      "             ReLU-13         [-1, 64, 256, 256]               0\n",
      "             ReLU-14         [-1, 64, 256, 256]               0\n",
      "    ResidualBlock-15         [-1, 64, 256, 256]               0\n",
      "ResidualInResidualBlock-16         [-1, 64, 256, 256]               0\n",
      "           Conv2d-17        [-1, 128, 128, 128]          73,856\n",
      "      BatchNorm2d-18        [-1, 128, 128, 128]             256\n",
      "             ReLU-19        [-1, 128, 128, 128]               0\n",
      "           Conv2d-20        [-1, 128, 128, 128]          16,384\n",
      "             ReLU-21        [-1, 128, 128, 128]               0\n",
      "           Conv2d-22        [-1, 128, 128, 128]         147,456\n",
      "      BatchNorm2d-23        [-1, 128, 128, 128]             256\n",
      "             ReLU-24        [-1, 128, 128, 128]               0\n",
      "             ReLU-25        [-1, 128, 128, 128]               0\n",
      "    ResidualBlock-26        [-1, 128, 128, 128]               0\n",
      "           Conv2d-27        [-1, 128, 128, 128]          16,384\n",
      "             ReLU-28        [-1, 128, 128, 128]               0\n",
      "           Conv2d-29        [-1, 128, 128, 128]         147,456\n",
      "      BatchNorm2d-30        [-1, 128, 128, 128]             256\n",
      "             ReLU-31        [-1, 128, 128, 128]               0\n",
      "             ReLU-32        [-1, 128, 128, 128]               0\n",
      "    ResidualBlock-33        [-1, 128, 128, 128]               0\n",
      "ResidualInResidualBlock-34        [-1, 128, 128, 128]               0\n",
      "           Conv2d-35          [-1, 256, 64, 64]         295,168\n",
      "      BatchNorm2d-36          [-1, 256, 64, 64]             512\n",
      "             ReLU-37          [-1, 256, 64, 64]               0\n",
      "           Conv2d-38          [-1, 256, 64, 64]          65,536\n",
      "             ReLU-39          [-1, 256, 64, 64]               0\n",
      "           Conv2d-40          [-1, 256, 64, 64]         589,824\n",
      "      BatchNorm2d-41          [-1, 256, 64, 64]             512\n",
      "             ReLU-42          [-1, 256, 64, 64]               0\n",
      "             ReLU-43          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-44          [-1, 256, 64, 64]               0\n",
      "           Conv2d-45          [-1, 256, 64, 64]          65,536\n",
      "             ReLU-46          [-1, 256, 64, 64]               0\n",
      "           Conv2d-47          [-1, 256, 64, 64]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 64, 64]             512\n",
      "             ReLU-49          [-1, 256, 64, 64]               0\n",
      "             ReLU-50          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-51          [-1, 256, 64, 64]               0\n",
      "ResidualInResidualBlock-52          [-1, 256, 64, 64]               0\n",
      "           Conv2d-53          [-1, 512, 32, 32]       1,180,160\n",
      "      BatchNorm2d-54          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-55          [-1, 512, 32, 32]               0\n",
      "           Conv2d-56          [-1, 512, 32, 32]         262,144\n",
      "             ReLU-57          [-1, 512, 32, 32]               0\n",
      "           Conv2d-58          [-1, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-59          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-60          [-1, 512, 32, 32]               0\n",
      "             ReLU-61          [-1, 512, 32, 32]               0\n",
      "    ResidualBlock-62          [-1, 512, 32, 32]               0\n",
      "           Conv2d-63          [-1, 512, 32, 32]         262,144\n",
      "             ReLU-64          [-1, 512, 32, 32]               0\n",
      "           Conv2d-65          [-1, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-66          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-67          [-1, 512, 32, 32]               0\n",
      "             ReLU-68          [-1, 512, 32, 32]               0\n",
      "    ResidualBlock-69          [-1, 512, 32, 32]               0\n",
      "ResidualInResidualBlock-70          [-1, 512, 32, 32]               0\n",
      "           Conv2d-71         [-1, 1024, 16, 16]       4,719,616\n",
      "      BatchNorm2d-72         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-73         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-74         [-1, 1024, 16, 16]       1,048,576\n",
      "             ReLU-75         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-76         [-1, 1024, 16, 16]       9,437,184\n",
      "      BatchNorm2d-77         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-78         [-1, 1024, 16, 16]               0\n",
      "             ReLU-79         [-1, 1024, 16, 16]               0\n",
      "    ResidualBlock-80         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-81         [-1, 1024, 16, 16]       1,048,576\n",
      "             ReLU-82         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-83         [-1, 1024, 16, 16]       9,437,184\n",
      "      BatchNorm2d-84         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-85         [-1, 1024, 16, 16]               0\n",
      "             ReLU-86         [-1, 1024, 16, 16]               0\n",
      "    ResidualBlock-87         [-1, 1024, 16, 16]               0\n",
      "ResidualInResidualBlock-88         [-1, 1024, 16, 16]               0\n",
      "  ConvTranspose2d-89          [-1, 512, 32, 32]       2,097,664\n",
      "           Conv2d-90         [-1, 1024, 32, 32]       1,048,576\n",
      "             ReLU-91         [-1, 1024, 32, 32]               0\n",
      "           Conv2d-92         [-1, 1024, 32, 32]       9,437,184\n",
      "      BatchNorm2d-93         [-1, 1024, 32, 32]           2,048\n",
      "             ReLU-94         [-1, 1024, 32, 32]               0\n",
      "             ReLU-95         [-1, 1024, 32, 32]               0\n",
      "    ResidualBlock-96         [-1, 1024, 32, 32]               0\n",
      "           Conv2d-97         [-1, 1024, 32, 32]       1,048,576\n",
      "             ReLU-98         [-1, 1024, 32, 32]               0\n",
      "           Conv2d-99         [-1, 1024, 32, 32]       9,437,184\n",
      "     BatchNorm2d-100         [-1, 1024, 32, 32]           2,048\n",
      "            ReLU-101         [-1, 1024, 32, 32]               0\n",
      "            ReLU-102         [-1, 1024, 32, 32]               0\n",
      "   ResidualBlock-103         [-1, 1024, 32, 32]               0\n",
      "ResidualInResidualBlock-104         [-1, 1024, 32, 32]               0\n",
      "          Conv2d-105          [-1, 512, 32, 32]       4,719,104\n",
      " ConvTranspose2d-106          [-1, 256, 64, 64]         524,544\n",
      "          Conv2d-107          [-1, 512, 64, 64]         262,144\n",
      "            ReLU-108          [-1, 512, 64, 64]               0\n",
      "          Conv2d-109          [-1, 512, 64, 64]       2,359,296\n",
      "     BatchNorm2d-110          [-1, 512, 64, 64]           1,024\n",
      "            ReLU-111          [-1, 512, 64, 64]               0\n",
      "            ReLU-112          [-1, 512, 64, 64]               0\n",
      "   ResidualBlock-113          [-1, 512, 64, 64]               0\n",
      "          Conv2d-114          [-1, 512, 64, 64]         262,144\n",
      "            ReLU-115          [-1, 512, 64, 64]               0\n",
      "          Conv2d-116          [-1, 512, 64, 64]       2,359,296\n",
      "     BatchNorm2d-117          [-1, 512, 64, 64]           1,024\n",
      "            ReLU-118          [-1, 512, 64, 64]               0\n",
      "            ReLU-119          [-1, 512, 64, 64]               0\n",
      "   ResidualBlock-120          [-1, 512, 64, 64]               0\n",
      "ResidualInResidualBlock-121          [-1, 512, 64, 64]               0\n",
      "          Conv2d-122          [-1, 256, 64, 64]       1,179,904\n",
      " ConvTranspose2d-123        [-1, 128, 128, 128]         131,200\n",
      "          Conv2d-124        [-1, 256, 128, 128]          65,536\n",
      "            ReLU-125        [-1, 256, 128, 128]               0\n",
      "          Conv2d-126        [-1, 256, 128, 128]         589,824\n",
      "     BatchNorm2d-127        [-1, 256, 128, 128]             512\n",
      "            ReLU-128        [-1, 256, 128, 128]               0\n",
      "            ReLU-129        [-1, 256, 128, 128]               0\n",
      "   ResidualBlock-130        [-1, 256, 128, 128]               0\n",
      "          Conv2d-131        [-1, 256, 128, 128]          65,536\n",
      "            ReLU-132        [-1, 256, 128, 128]               0\n",
      "          Conv2d-133        [-1, 256, 128, 128]         589,824\n",
      "     BatchNorm2d-134        [-1, 256, 128, 128]             512\n",
      "            ReLU-135        [-1, 256, 128, 128]               0\n",
      "            ReLU-136        [-1, 256, 128, 128]               0\n",
      "   ResidualBlock-137        [-1, 256, 128, 128]               0\n",
      "ResidualInResidualBlock-138        [-1, 256, 128, 128]               0\n",
      "          Conv2d-139        [-1, 128, 128, 128]         295,040\n",
      " ConvTranspose2d-140         [-1, 64, 256, 256]          32,832\n",
      "          Conv2d-141        [-1, 128, 256, 256]          16,384\n",
      "            ReLU-142        [-1, 128, 256, 256]               0\n",
      "          Conv2d-143        [-1, 128, 256, 256]         147,456\n",
      "     BatchNorm2d-144        [-1, 128, 256, 256]             256\n",
      "            ReLU-145        [-1, 128, 256, 256]               0\n",
      "            ReLU-146        [-1, 128, 256, 256]               0\n",
      "   ResidualBlock-147        [-1, 128, 256, 256]               0\n",
      "          Conv2d-148        [-1, 128, 256, 256]          16,384\n",
      "            ReLU-149        [-1, 128, 256, 256]               0\n",
      "          Conv2d-150        [-1, 128, 256, 256]         147,456\n",
      "     BatchNorm2d-151        [-1, 128, 256, 256]             256\n",
      "            ReLU-152        [-1, 128, 256, 256]               0\n",
      "            ReLU-153        [-1, 128, 256, 256]               0\n",
      "   ResidualBlock-154        [-1, 128, 256, 256]               0\n",
      "ResidualInResidualBlock-155        [-1, 128, 256, 256]               0\n",
      "          Conv2d-156         [-1, 64, 256, 256]          73,792\n",
      "          Conv2d-157          [-1, 3, 256, 256]           1,731\n",
      "         Sigmoid-158          [-1, 3, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 71,133,379\n",
      "Trainable params: 71,133,379\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 2975.00\n",
      "Params size (MB): 271.35\n",
      "Estimated Total Size (MB): 3246.40\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_1 = UNetSRx4RiR(3, 3, 64, 0.0)\n",
    "model_1.to(device)\n",
    "summary(model_1, input_size=(3, 64, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7624529-7ab0-45a5-8f06-546fed9e444f",
   "metadata": {},
   "source": [
    "## Defining Loss Functions and Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5907b081-4563-4fa1-b3d0-7621f6307f41",
   "metadata": {},
   "source": [
    "### Defining PSNR metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bc1066c-fd8d-43f5-88ba-71f51ffb73a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(img1, img2, max_pixel_value=1.0):\n",
    "    mse = torch.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    psnr = 10 * torch.log10((max_pixel_value ** 2) / mse)\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1318f0b4-b248-4a86-ac68-36c786ceefac",
   "metadata": {},
   "source": [
    "### Defining Tukey Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71a4df9e-5e1a-4912-85a3-04bde20d39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TukeyLoss(nn.Module):\n",
    "    def __init__(self, c=0.3):  # Adjusted c value for normalized data\n",
    "        super(TukeyLoss, self).__init__()\n",
    "        self.c = c\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        error = input - target\n",
    "        abs_error = torch.abs(error)\n",
    "\n",
    "        # Tukey loss calculation\n",
    "        mask = abs_error <= self.c\n",
    "        tukey_loss = torch.where(\n",
    "            mask,\n",
    "            (self.c ** 2 / 6) * (1 - (1 - (error / self.c) ** 2) ** 3),\n",
    "            (self.c ** 2 / 6) * torch.ones_like(error)\n",
    "        )\n",
    "\n",
    "        return tukey_loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ecdb0-8f32-4089-80e5-0ebda494f509",
   "metadata": {},
   "source": [
    "### Defining Charbonnier loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05601d49-9ad7-4777-a3b4-61a37519202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharbonnierLoss(nn.Module):\n",
    "    def __init__(self, epsilon=1e-3):\n",
    "        super(CharbonnierLoss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        diff = x - y\n",
    "        loss = torch.mean(torch.sqrt(diff * diff + self.epsilon ** 2))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7970d5-e54b-4198-8b41-38ad2fc88e38",
   "metadata": {},
   "source": [
    "### Defining Total Variation (TV) loss and combined TV + MAE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a040a7b6-a2a9-42a9-a6ed-37b3ff9eadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TVLoss(nn.Module):\n",
    "    def __init__(self, tv_weight=1e-4):\n",
    "        super(TVLoss, self).__init__()\n",
    "        self.tv_weight = tv_weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h_x = x.size(2)\n",
    "        w_x = x.size(3)\n",
    "        count_h = self._tensor_size(x[:, :, 1:, :])\n",
    "        count_w = self._tensor_size(x[:, :, :, 1:])\n",
    "        h_tv = torch.pow(x[:, :, 1:, :] - x[:, :, :-1, :], 2).sum()\n",
    "        w_tv = torch.pow(x[:, :, :, 1:] - x[:, :, :, :-1], 2).sum()\n",
    "        return self.tv_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def _tensor_size(t):\n",
    "        return t.size(1) * t.size(2) * t.size(3)\n",
    "    \n",
    "def combined_tv_mae_loss(output, target):\n",
    "    \"\"\"Calculate combined MAE and TV loss.\"\"\"\n",
    "    mae_loss = l1_loss(output, target)\n",
    "    tv_out = tv_loss(output)\n",
    "    return tv_out + mae_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956fb3b1-3ef0-4bd9-a1a2-f58c4bb7acc3",
   "metadata": {},
   "source": [
    "### Defining combined SSIM loss + MAE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03a4db8e-a45b-4f9b-8636-a9d5d99b9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_ssim_l1_loss(output, target, alpha=0.7):\n",
    "    ssim_out = 1 - ssim(output, target, data_range=1.0)\n",
    "    mae_loss = torch.nn.functional.l1_loss(output, target)\n",
    "    return alpha * mae_loss + (1 - alpha) * ssim_out + 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d194e5f-bebf-42de-956a-a9c0d81286f9",
   "metadata": {},
   "source": [
    "### Defining Early Stopping class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33da6ebd-c3ba-41c8-ab56-57ec248ea37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5dfc9f-b753-42da-b4ce-bd4dd80116ea",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bca14a-0a3c-4810-8a64-eb02f3d70a97",
   "metadata": {},
   "source": [
    "### Training the model for MAE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed2b1ba-af80-484c-8a03-b317616e6a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 04:55:39.783390: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-07 04:55:39.938763: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-07 04:55:40.670297: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-07 04:55:40.670367: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-07 04:55:40.670375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Epoch 1/25: 100%|██████████| 1182/1182 [23:22<00:00,  1.19s/batch, loss=0.0443]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train Loss: 0.0471, Train PSNR: 23.4607, Train SSIM: 0.7081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0338, Validation PSNR: 25.0414, Validation SSIM: 0.7598\n",
      "Validation loss decreased (inf --> 0.033751).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25: 100%|██████████| 1182/1182 [23:23<00:00,  1.19s/batch, loss=0.0268]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25], Train Loss: 0.0350, Train PSNR: 24.9670, Train SSIM: 0.7618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0310, Validation PSNR: 25.4650, Validation SSIM: 0.7786\n",
      "Validation loss decreased (0.033751 --> 0.030954).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25: 100%|██████████| 1182/1182 [23:24<00:00,  1.19s/batch, loss=0.0218]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Train Loss: 0.0324, Train PSNR: 25.3283, Train SSIM: 0.7749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0314, Validation PSNR: 25.5211, Validation SSIM: 0.7861\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25: 100%|██████████| 1182/1182 [23:25<00:00,  1.19s/batch, loss=0.0442]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25], Train Loss: 0.0310, Train PSNR: 25.5430, Train SSIM: 0.7819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0296, Validation PSNR: 25.7119, Validation SSIM: 0.7874\n",
      "Validation loss decreased (0.030954 --> 0.029613).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25: 100%|██████████| 1182/1182 [23:24<00:00,  1.19s/batch, loss=0.026] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Train Loss: 0.0302, Train PSNR: 25.6532, Train SSIM: 0.7865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0292, Validation PSNR: 25.7905, Validation SSIM: 0.7906\n",
      "Validation loss decreased (0.029613 --> 0.029197).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25: 100%|██████████| 1182/1182 [23:25<00:00,  1.19s/batch, loss=0.0337]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25], Train Loss: 0.0296, Train PSNR: 25.7612, Train SSIM: 0.7899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0282, Validation PSNR: 25.8957, Validation SSIM: 0.7941\n",
      "Validation loss decreased (0.029197 --> 0.028229).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25: 100%|██████████| 1182/1182 [23:25<00:00,  1.19s/batch, loss=0.0225]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Train Loss: 0.0291, Train PSNR: 25.8263, Train SSIM: 0.7927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0275, Validation PSNR: 25.9694, Validation SSIM: 0.7973\n",
      "Validation loss decreased (0.028229 --> 0.027493).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/25: 100%|██████████| 1182/1182 [23:24<00:00,  1.19s/batch, loss=0.031] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25], Train Loss: 0.0288, Train PSNR: 25.9014, Train SSIM: 0.7948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0277, Validation PSNR: 25.9596, Validation SSIM: 0.7988\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/25: 100%|██████████| 1182/1182 [23:24<00:00,  1.19s/batch, loss=0.0444]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25], Train Loss: 0.0283, Train PSNR: 25.9511, Train SSIM: 0.7969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0282, Validation PSNR: 25.8762, Validation SSIM: 0.7927\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/25: 100%|██████████| 1182/1182 [23:23<00:00,  1.19s/batch, loss=0.0347]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25], Train Loss: 0.0281, Train PSNR: 25.9692, Train SSIM: 0.7981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0286, Validation PSNR: 25.9306, Validation SSIM: 0.8002\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 00010: reducing learning rate of group 0 to 2.5000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25: 100%|██████████| 1182/1182 [23:23<00:00,  1.19s/batch, loss=0.0261]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/25], Train Loss: 0.0271, Train PSNR: 26.1101, Train SSIM: 0.8014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0266, Validation PSNR: 26.1135, Validation SSIM: 0.8026\n",
      "Validation loss decreased (0.027493 --> 0.026587).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25: 100%|██████████| 1182/1182 [23:23<00:00,  1.19s/batch, loss=0.0118]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/25], Train Loss: 0.0270, Train PSNR: 26.1436, Train SSIM: 0.8026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0271, Validation PSNR: 26.1051, Validation SSIM: 0.8037\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25: 100%|██████████| 1182/1182 [23:22<00:00,  1.19s/batch, loss=0.0349]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/25], Train Loss: 0.0268, Train PSNR: 26.1325, Train SSIM: 0.8033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0269, Validation PSNR: 26.1289, Validation SSIM: 0.8032\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/25: 100%|██████████| 1182/1182 [23:22<00:00,  1.19s/batch, loss=0.0241]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/25], Train Loss: 0.0267, Train PSNR: 26.1934, Train SSIM: 0.8041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0265, Validation PSNR: 26.1533, Validation SSIM: 0.8073\n",
      "Validation loss decreased (0.026587 --> 0.026497).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/25: 100%|██████████| 1182/1182 [23:22<00:00,  1.19s/batch, loss=0.0282]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25], Train Loss: 0.0267, Train PSNR: 26.1998, Train SSIM: 0.8047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0267, Validation PSNR: 26.1728, Validation SSIM: 0.8047\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/25: 100%|██████████| 1182/1182 [23:22<00:00,  1.19s/batch, loss=0.0231]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/25], Train Loss: 0.0265, Train PSNR: 26.2153, Train SSIM: 0.8054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0275, Validation PSNR: 26.1121, Validation SSIM: 0.8050\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/25: 100%|██████████| 1182/1182 [23:23<00:00,  1.19s/batch, loss=0.0343]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/25], Train Loss: 0.0265, Train PSNR: 26.2195, Train SSIM: 0.8058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0266, Validation PSNR: 26.1921, Validation SSIM: 0.8075\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 00017: reducing learning rate of group 0 to 1.2500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/25: 100%|██████████| 1182/1182 [23:22<00:00,  1.19s/batch, loss=0.044] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/25], Train Loss: 0.0260, Train PSNR: 26.2633, Train SSIM: 0.8075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0266, Validation PSNR: 26.1954, Validation SSIM: 0.8071\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/25: 100%|██████████| 1182/1182 [23:21<00:00,  1.19s/batch, loss=0.0241]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/25], Train Loss: 0.0260, Train PSNR: 26.3188, Train SSIM: 0.8081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0262, Validation PSNR: 26.2290, Validation SSIM: 0.8081\n",
      "Validation loss decreased (0.026497 --> 0.026174).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/25: 100%|██████████| 1182/1182 [23:21<00:00,  1.19s/batch, loss=0.0228]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25], Train Loss: 0.0259, Train PSNR: 26.3016, Train SSIM: 0.8085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0260, Validation PSNR: 26.2425, Validation SSIM: 0.8079\n",
      "Validation loss decreased (0.026174 --> 0.026030).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/25: 100%|██████████| 1182/1182 [23:22<00:00,  1.19s/batch, loss=0.0417]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/25], Train Loss: 0.0259, Train PSNR: 26.3158, Train SSIM: 0.8089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0260, Validation PSNR: 26.2444, Validation SSIM: 0.8082\n",
      "Validation loss decreased (0.026030 --> 0.026021).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/25: 100%|██████████| 1182/1182 [23:23<00:00,  1.19s/batch, loss=0.0413]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/25], Train Loss: 0.0258, Train PSNR: 26.3482, Train SSIM: 0.8092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0260, Validation PSNR: 26.2419, Validation SSIM: 0.8091\n",
      "Validation loss decreased (0.026021 --> 0.025996).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/25: 100%|██████████| 1182/1182 [23:22<00:00,  1.19s/batch, loss=0.0308]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/25], Train Loss: 0.0258, Train PSNR: 26.3186, Train SSIM: 0.8096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0259, Validation PSNR: 26.2640, Validation SSIM: 0.8089\n",
      "Validation loss decreased (0.025996 --> 0.025868).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/25: 100%|██████████| 1182/1182 [23:21<00:00,  1.19s/batch, loss=0.0217]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/25], Train Loss: 0.0258, Train PSNR: 26.3511, Train SSIM: 0.8098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0258, Validation PSNR: 26.2700, Validation SSIM: 0.8102\n",
      "Validation loss decreased (0.025868 --> 0.025831).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/25: 100%|█████████▉| 1180/1182 [23:21<00:02,  1.19s/batch, loss=0.0265]"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = UNetSRx4RiR(in_channels=3, out_channels=3, num_features=64, dropout_rate=0.0).to(device)\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Initialize TensorBoard writer\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter('runs/UNetSRx4_L1_fin')\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "    \n",
    "    # Initialize learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    num_epochs = 25\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_psnr = 0.0\n",
    "        running_ssim = 0.0\n",
    "\n",
    "        # Wrap the train_loader with tqdm for progress bar\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        \n",
    "        for i, (hr_patches, lr_patches) in enumerate(progress_bar):\n",
    "            hr_patches, lr_patches = hr_patches.to(device), lr_patches.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                outputs = model(lr_patches)\n",
    "                loss = criterion(outputs, hr_patches)\n",
    "                if torch.isnan(loss).any():\n",
    "                    print(\"Loss is NaN\")\n",
    "                    break\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_psnr += calculate_psnr(outputs, hr_patches).item()\n",
    "            outputs = outputs.float()\n",
    "            hr_patches = hr_patches.float()\n",
    "            running_ssim += ssim(outputs, hr_patches, data_range=1.0).item()\n",
    "\n",
    "            # Update the progress bar with the running loss\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        avg_train_psnr = running_psnr / len(train_loader)\n",
    "        avg_train_ssim = running_ssim / len(train_loader)\n",
    "        writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "        writer.add_scalar('PSNR/train', avg_train_psnr, epoch)\n",
    "        writer.add_scalar('SSIM/train', avg_train_ssim, epoch)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train PSNR: {avg_train_psnr:.4f}, Train SSIM: {avg_train_ssim:.4f}')\n",
    "    \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_psnr = 0.0\n",
    "        val_ssim = 0.0     \n",
    "        with torch.no_grad():\n",
    "            for hr_patches, lr_patches in val_loader:\n",
    "                hr_patches, lr_patches = hr_patches.to(device), lr_patches.to(device)\n",
    "                with autocast(enabled=True):\n",
    "                    outputs = model(lr_patches)\n",
    "                    loss = criterion(outputs, hr_patches)\n",
    "                    if torch.isnan(loss).any():\n",
    "                        print(\"Loss is NaN\")\n",
    "                        break\n",
    "                val_loss += loss.item()\n",
    "                val_psnr += calculate_psnr(outputs, hr_patches).item()\n",
    "                # Convert to float32 before calculating SSIM\n",
    "                outputs = outputs.float()\n",
    "                hr_patches = hr_patches.float()\n",
    "                val_ssim += ssim(outputs, hr_patches, data_range=1.0).item()\n",
    "    \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_psnr = val_psnr / len(val_loader)\n",
    "        avg_val_ssim = val_ssim / len(val_loader)\n",
    "        writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "        writer.add_scalar('PSNR/val', avg_val_psnr, epoch)\n",
    "        writer.add_scalar('SSIM/val', avg_val_ssim, epoch)\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}, Validation PSNR: {avg_val_psnr:.4f}, Validation SSIM: {avg_val_ssim:.4f}')\n",
    "\n",
    "        # Check early stopping condition\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "    \n",
    "    print('Training complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562a3ed5-d663-4067-8123-9d52ea5d8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"UNet_L1_final.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b63d0d-e1c3-4c95-9a2c-7d57e703728b",
   "metadata": {},
   "source": [
    "### Training the model for MSE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6b8c070-16ac-4ba6-bfe7-f38a5c58ac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25: 100%|██████████| 1182/1182 [25:41<00:00,  1.30s/batch, loss=0.00643]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train Loss: 0.0048, Train PSNR: 23.6951, Train SSIM: 0.7243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0032, Validation PSNR: 25.1840, Validation SSIM: 0.7579\n",
      "Validation loss decreased (inf --> 0.003196).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25: 100%|██████████| 1182/1182 [23:18<00:00,  1.18s/batch, loss=0.008]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25], Train Loss: 0.0032, Train PSNR: 25.1770, Train SSIM: 0.7694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0032, Validation PSNR: 25.2142, Validation SSIM: 0.7714\n",
      "Validation loss decreased (0.003196 --> 0.003168).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25: 100%|██████████| 1182/1182 [23:18<00:00,  1.18s/batch, loss=0.0029]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Train Loss: 0.0030, Train PSNR: 25.4919, Train SSIM: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0028, Validation PSNR: 25.7216, Validation SSIM: 0.7849\n",
      "Validation loss decreased (0.003168 --> 0.002848).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25: 100%|██████████| 1182/1182 [23:18<00:00,  1.18s/batch, loss=0.00875]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25], Train Loss: 0.0029, Train PSNR: 25.7035, Train SSIM: 0.7853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0028, Validation PSNR: 25.7427, Validation SSIM: 0.7836\n",
      "Validation loss decreased (0.002848 --> 0.002832).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25: 100%|██████████| 1182/1182 [23:18<00:00,  1.18s/batch, loss=0.000963]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Train Loss: 0.0028, Train PSNR: 25.7884, Train SSIM: 0.7889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0032, Validation PSNR: 25.2679, Validation SSIM: 0.7767\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25: 100%|██████████| 1182/1182 [23:21<00:00,  1.19s/batch, loss=0.00404]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25], Train Loss: 0.0028, Train PSNR: 25.8172, Train SSIM: 0.7893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0028, Validation PSNR: 25.7982, Validation SSIM: 0.7872\n",
      "Validation loss decreased (0.002832 --> 0.002809).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25: 100%|██████████| 1182/1182 [23:22<00:00,  1.19s/batch, loss=0.00152]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Train Loss: 0.0027, Train PSNR: 25.9402, Train SSIM: 0.7932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0028, Validation PSNR: 25.8125, Validation SSIM: 0.7930\n",
      "Validation loss decreased (0.002809 --> 0.002786).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/25: 100%|██████████| 1182/1182 [23:25<00:00,  1.19s/batch, loss=0.00232] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25], Train Loss: 0.0027, Train PSNR: 25.9980, Train SSIM: 0.7953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0028, Validation PSNR: 25.7723, Validation SSIM: 0.7816\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/25: 100%|██████████| 1182/1182 [23:25<00:00,  1.19s/batch, loss=0.0144]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25], Train Loss: 0.0027, Train PSNR: 26.0056, Train SSIM: 0.7959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0026, Validation PSNR: 26.0768, Validation SSIM: 0.7960\n",
      "Validation loss decreased (0.002786 --> 0.002638).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/25: 100%|██████████| 1182/1182 [23:26<00:00,  1.19s/batch, loss=0.002]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25], Train Loss: 0.0026, Train PSNR: 26.0539, Train SSIM: 0.7983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0034, Validation PSNR: 25.0126, Validation SSIM: 0.7710\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25: 100%|██████████| 1182/1182 [23:27<00:00,  1.19s/batch, loss=0.00118] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/25], Train Loss: 0.0026, Train PSNR: 26.1054, Train SSIM: 0.7991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0029, Validation PSNR: 25.5884, Validation SSIM: 0.7880\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25: 100%|██████████| 1182/1182 [23:29<00:00,  1.19s/batch, loss=0.00679] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/25], Train Loss: 0.0026, Train PSNR: 26.1235, Train SSIM: 0.8004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0026, Validation PSNR: 26.1958, Validation SSIM: 0.8009\n",
      "Validation loss decreased (0.002638 --> 0.002572).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25: 100%|██████████| 1182/1182 [23:29<00:00,  1.19s/batch, loss=0.0025]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/25], Train Loss: 0.0026, Train PSNR: 26.1774, Train SSIM: 0.8018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0027, Validation PSNR: 25.9753, Validation SSIM: 0.7966\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/25: 100%|██████████| 1182/1182 [23:30<00:00,  1.19s/batch, loss=0.00187] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/25], Train Loss: 0.0026, Train PSNR: 26.1956, Train SSIM: 0.8010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0026, Validation PSNR: 26.1362, Validation SSIM: 0.8000\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/25: 100%|██████████| 1182/1182 [23:32<00:00,  1.19s/batch, loss=0.00073] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25], Train Loss: 0.0026, Train PSNR: 26.2152, Train SSIM: 0.8034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0027, Validation PSNR: 25.9322, Validation SSIM: 0.7971\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 00015: reducing learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/25: 100%|██████████| 1182/1182 [23:30<00:00,  1.19s/batch, loss=0.00362] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/25], Train Loss: 0.0025, Train PSNR: 26.3441, Train SSIM: 0.8066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0026, Validation PSNR: 26.2225, Validation SSIM: 0.8023\n",
      "Validation loss decreased (0.002572 --> 0.002557).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/25: 100%|██████████| 1182/1182 [23:29<00:00,  1.19s/batch, loss=0.00132] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/25], Train Loss: 0.0025, Train PSNR: 26.3697, Train SSIM: 0.8073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0026, Validation PSNR: 26.1714, Validation SSIM: 0.8032\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/25: 100%|██████████| 1182/1182 [23:30<00:00,  1.19s/batch, loss=0.00247] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/25], Train Loss: 0.0025, Train PSNR: 26.3721, Train SSIM: 0.8077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0025, Validation PSNR: 26.2374, Validation SSIM: 0.8025\n",
      "Validation loss decreased (0.002557 --> 0.002545).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/25: 100%|██████████| 1182/1182 [23:32<00:00,  1.19s/batch, loss=0.00299] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/25], Train Loss: 0.0025, Train PSNR: 26.3594, Train SSIM: 0.8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0026, Validation PSNR: 26.1002, Validation SSIM: 0.8024\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/25: 100%|██████████| 1182/1182 [23:31<00:00,  1.19s/batch, loss=0.0018]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25], Train Loss: 0.0025, Train PSNR: 26.4157, Train SSIM: 0.8087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0027, Validation PSNR: 26.0875, Validation SSIM: 0.8029\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/25: 100%|██████████| 1182/1182 [23:33<00:00,  1.20s/batch, loss=0.00167] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/25], Train Loss: 0.0025, Train PSNR: 26.4230, Train SSIM: 0.8091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0025, Validation PSNR: 26.3188, Validation SSIM: 0.8043\n",
      "Validation loss decreased (0.002545 --> 0.002501).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/25: 100%|██████████| 1182/1182 [23:32<00:00,  1.19s/batch, loss=0.000775]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/25], Train Loss: 0.0024, Train PSNR: 26.4401, Train SSIM: 0.8097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0039, Validation PSNR: 25.1265, Validation SSIM: 0.7962\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/25: 100%|██████████| 1182/1182 [23:33<00:00,  1.20s/batch, loss=0.00112] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/25], Train Loss: 0.0024, Train PSNR: 26.4512, Train SSIM: 0.8099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0025, Validation PSNR: 26.2909, Validation SSIM: 0.8045\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/25: 100%|██████████| 1182/1182 [23:32<00:00,  1.19s/batch, loss=0.00234] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/25], Train Loss: 0.0024, Train PSNR: 26.4427, Train SSIM: 0.8101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0027, Validation PSNR: 26.0393, Validation SSIM: 0.8028\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 00024: reducing learning rate of group 0 to 2.5000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/25: 100%|██████████| 1182/1182 [23:32<00:00,  1.20s/batch, loss=0.00137] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25], Train Loss: 0.0024, Train PSNR: 26.5032, Train SSIM: 0.8119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0025, Validation PSNR: 26.3680, Validation SSIM: 0.8077\n",
      "Validation loss decreased (0.002501 --> 0.002475).  Saving model ...\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = UNetSRx4RiR(in_channels=3, out_channels=3, num_features=64, dropout_rate=0.0).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Initialize TensorBoard writer\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter('runs/UNetSRx4_L2')\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "    \n",
    "    # Initialize learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    num_epochs = 25\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_psnr = 0.0\n",
    "        running_ssim = 0.0\n",
    "\n",
    "        # Wrap the train_loader with tqdm for progress bar\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        \n",
    "        for i, (hr_patches, lr_patches) in enumerate(progress_bar):\n",
    "            hr_patches, lr_patches = hr_patches.to(device), lr_patches.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                outputs = model(lr_patches)\n",
    "                loss = criterion(outputs, hr_patches)\n",
    "                if torch.isnan(loss).any():\n",
    "                    print(\"Loss is NaN\")\n",
    "                    break\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_psnr += calculate_psnr(outputs, hr_patches).item()\n",
    "            outputs = outputs.float()\n",
    "            hr_patches = hr_patches.float()\n",
    "            running_ssim += ssim(outputs, hr_patches, data_range=1.0).item()\n",
    "\n",
    "            # Update the progress bar with the running loss\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        avg_train_psnr = running_psnr / len(train_loader)\n",
    "        avg_train_ssim = running_ssim / len(train_loader)\n",
    "        writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "        writer.add_scalar('PSNR/train', avg_train_psnr, epoch)\n",
    "        writer.add_scalar('SSIM/train', avg_train_ssim, epoch)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train PSNR: {avg_train_psnr:.4f}, Train SSIM: {avg_train_ssim:.4f}')\n",
    "    \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_psnr = 0.0\n",
    "        val_ssim = 0.0     \n",
    "        with torch.no_grad():\n",
    "            for hr_patches, lr_patches in val_loader:\n",
    "                hr_patches, lr_patches = hr_patches.to(device), lr_patches.to(device)\n",
    "                with autocast(enabled=True):\n",
    "                    outputs = model(lr_patches)\n",
    "                    loss = criterion(outputs, hr_patches)\n",
    "                    if torch.isnan(loss).any():\n",
    "                        print(\"Loss is NaN\")\n",
    "                        break\n",
    "                val_loss += loss.item()\n",
    "                val_psnr += calculate_psnr(outputs, hr_patches).item()\n",
    "                # Convert to float32 before calculating SSIM\n",
    "                outputs = outputs.float()\n",
    "                hr_patches = hr_patches.float()\n",
    "                val_ssim += ssim(outputs, hr_patches, data_range=1.0).item()\n",
    "    \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_psnr = val_psnr / len(val_loader)\n",
    "        avg_val_ssim = val_ssim / len(val_loader)\n",
    "        writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "        writer.add_scalar('PSNR/val', avg_val_psnr, epoch)\n",
    "        writer.add_scalar('SSIM/val', avg_val_ssim, epoch)\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}, Validation PSNR: {avg_val_psnr:.4f}, Validation SSIM: {avg_val_ssim:.4f}')\n",
    "\n",
    "        # Check early stopping condition\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "    \n",
    "    print('Training complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "734d07c8-90a9-4922-af53-68358ab66ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"UNet_L2_final.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae29d0-4e10-4306-912f-23f73f8857bb",
   "metadata": {},
   "source": [
    "### Training the model for Tukey loss (C = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f0f6488-b0ab-4e93-be22-2ac4b5bd434a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 17:53:37.455563: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-01 17:53:37.595472: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-01 17:53:38.294487: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-01 17:53:38.294561: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-01 17:53:38.294569: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Epoch 1/25: 100%|██████████| 1182/1182 [23:07<00:00,  1.17s/batch, loss=0.00202] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train Loss: 0.0016, Train PSNR: 23.7686, Train SSIM: 0.7276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0010, Validation PSNR: 25.4096, Validation SSIM: 0.7745\n",
      "Validation loss decreased (inf --> 0.001032).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25: 100%|██████████| 1182/1182 [23:06<00:00,  1.17s/batch, loss=0.000624]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25], Train Loss: 0.0011, Train PSNR: 25.2389, Train SSIM: 0.7747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0010, Validation PSNR: 25.7575, Validation SSIM: 0.7839\n",
      "Validation loss decreased (0.001032 --> 0.000957).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25: 100%|██████████| 1182/1182 [23:07<00:00,  1.17s/batch, loss=0.00142] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Train Loss: 0.0010, Train PSNR: 25.5453, Train SSIM: 0.7841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0010, Validation PSNR: 25.4694, Validation SSIM: 0.7880\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25: 100%|██████████| 1182/1182 [23:08<00:00,  1.17s/batch, loss=0.000908]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25], Train Loss: 0.0010, Train PSNR: 25.6855, Train SSIM: 0.7895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0009, Validation PSNR: 25.9637, Validation SSIM: 0.7889\n",
      "Validation loss decreased (0.000957 --> 0.000913).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25: 100%|██████████| 1182/1182 [23:09<00:00,  1.18s/batch, loss=0.000859]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Train Loss: 0.0009, Train PSNR: 25.8234, Train SSIM: 0.7930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0009, Validation PSNR: 26.0153, Validation SSIM: 0.7978\n",
      "Validation loss decreased (0.000913 --> 0.000900).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25: 100%|██████████| 1182/1182 [23:10<00:00,  1.18s/batch, loss=0.00119] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25], Train Loss: 0.0009, Train PSNR: 25.8832, Train SSIM: 0.7952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0009, Validation PSNR: 25.9024, Validation SSIM: 0.7983\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25: 100%|██████████| 1182/1182 [23:11<00:00,  1.18s/batch, loss=0.000317]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Train Loss: 0.0009, Train PSNR: 25.9626, Train SSIM: 0.7981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0009, Validation PSNR: 26.0827, Validation SSIM: 0.8015\n",
      "Validation loss decreased (0.000900 --> 0.000890).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/25: 100%|██████████| 1182/1182 [23:11<00:00,  1.18s/batch, loss=0.00153] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25], Train Loss: 0.0009, Train PSNR: 25.9923, Train SSIM: 0.7996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0009, Validation PSNR: 26.1851, Validation SSIM: 0.8041\n",
      "Validation loss decreased (0.000890 --> 0.000871).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/25: 100%|██████████| 1182/1182 [23:12<00:00,  1.18s/batch, loss=0.000549]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25], Train Loss: 0.0009, Train PSNR: 26.0511, Train SSIM: 0.8008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0009, Validation PSNR: 26.1436, Validation SSIM: 0.7966\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/25: 100%|██████████| 1182/1182 [23:12<00:00,  1.18s/batch, loss=0.000881]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25], Train Loss: 0.0009, Train PSNR: 26.1100, Train SSIM: 0.8028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0009, Validation PSNR: 26.1679, Validation SSIM: 0.8051\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25: 100%|██████████| 1182/1182 [23:15<00:00,  1.18s/batch, loss=0.000349]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/25], Train Loss: 0.0009, Train PSNR: 26.1385, Train SSIM: 0.8039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0009, Validation PSNR: 26.1200, Validation SSIM: 0.8037\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 00011: reducing learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25: 100%|██████████| 1182/1182 [23:15<00:00,  1.18s/batch, loss=0.000546]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/25], Train Loss: 0.0008, Train PSNR: 26.2438, Train SSIM: 0.8072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0008, Validation PSNR: 26.2961, Validation SSIM: 0.8063\n",
      "Validation loss decreased (0.000871 --> 0.000844).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25: 100%|██████████| 1182/1182 [23:17<00:00,  1.18s/batch, loss=0.000903]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/25], Train Loss: 0.0008, Train PSNR: 26.2781, Train SSIM: 0.8078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0009, Validation PSNR: 26.1882, Validation SSIM: 0.8082\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/25: 100%|██████████| 1182/1182 [23:18<00:00,  1.18s/batch, loss=0.000656]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/25], Train Loss: 0.0008, Train PSNR: 26.2705, Train SSIM: 0.8083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0009, Validation PSNR: 26.2512, Validation SSIM: 0.8034\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/25: 100%|██████████| 1182/1182 [23:19<00:00,  1.18s/batch, loss=0.000488]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25], Train Loss: 0.0008, Train PSNR: 26.2863, Train SSIM: 0.8090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0008, Validation PSNR: 26.3992, Validation SSIM: 0.8104\n",
      "Validation loss decreased (0.000844 --> 0.000830).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/25: 100%|██████████| 1182/1182 [23:21<00:00,  1.19s/batch, loss=0.00164] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/25], Train Loss: 0.0008, Train PSNR: 26.3229, Train SSIM: 0.8096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0008, Validation PSNR: 26.4150, Validation SSIM: 0.8111\n",
      "Validation loss decreased (0.000830 --> 0.000826).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/25: 100%|██████████| 1182/1182 [23:21<00:00,  1.19s/batch, loss=0.00069] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/25], Train Loss: 0.0008, Train PSNR: 26.3318, Train SSIM: 0.8098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0008, Validation PSNR: 26.4138, Validation SSIM: 0.8097\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/25: 100%|██████████| 1182/1182 [23:20<00:00,  1.18s/batch, loss=0.000941]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/25], Train Loss: 0.0008, Train PSNR: 26.3245, Train SSIM: 0.8105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0008, Validation PSNR: 26.3849, Validation SSIM: 0.8130\n",
      "Validation loss decreased (0.000826 --> 0.000824).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/25: 100%|██████████| 1182/1182 [23:20<00:00,  1.18s/batch, loss=0.000869]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/25], Train Loss: 0.0008, Train PSNR: 26.3521, Train SSIM: 0.8109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0008, Validation PSNR: 26.1917, Validation SSIM: 0.8103\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/25: 100%|██████████| 1182/1182 [23:20<00:00,  1.19s/batch, loss=0.00226] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25], Train Loss: 0.0008, Train PSNR: 26.3403, Train SSIM: 0.8113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0008, Validation PSNR: 26.0074, Validation SSIM: 0.8089\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/25: 100%|██████████| 1182/1182 [23:21<00:00,  1.19s/batch, loss=0.00123] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/25], Train Loss: 0.0008, Train PSNR: 26.3725, Train SSIM: 0.8115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0008, Validation PSNR: 26.4476, Validation SSIM: 0.8121\n",
      "Validation loss decreased (0.000824 --> 0.000822).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/25: 100%|██████████| 1182/1182 [23:19<00:00,  1.18s/batch, loss=0.000695]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/25], Train Loss: 0.0008, Train PSNR: 26.3990, Train SSIM: 0.8122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0008, Validation PSNR: 26.3637, Validation SSIM: 0.8101\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/25: 100%|██████████| 1182/1182 [23:20<00:00,  1.18s/batch, loss=0.00109] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/25], Train Loss: 0.0008, Train PSNR: 26.4172, Train SSIM: 0.8124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0008, Validation PSNR: 26.4527, Validation SSIM: 0.8124\n",
      "Validation loss decreased (0.000822 --> 0.000821).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/25: 100%|██████████| 1182/1182 [23:21<00:00,  1.19s/batch, loss=0.000339]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/25], Train Loss: 0.0008, Train PSNR: 26.4036, Train SSIM: 0.8130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0008, Validation PSNR: 26.1608, Validation SSIM: 0.8085\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/25: 100%|██████████| 1182/1182 [23:21<00:00,  1.19s/batch, loss=0.00037] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25], Train Loss: 0.0008, Train PSNR: 26.4178, Train SSIM: 0.8130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0008, Validation PSNR: 26.4577, Validation SSIM: 0.8140\n",
      "Validation loss decreased (0.000821 --> 0.000818).  Saving model ...\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = UNetSRx4RiR(in_channels=3, out_channels=3, num_features=64, dropout_rate=0.0).to(device)\n",
    "    criterion = TukeyLoss(c=0.3)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Initialize TensorBoard writer\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter('runs/UNetSRx4_Tukey')\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "    \n",
    "    # Initialize learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    num_epochs = 25\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_psnr = 0.0\n",
    "        running_ssim = 0.0\n",
    "\n",
    "        # Wrap the train_loader with tqdm for progress bar\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        \n",
    "        for i, (hr_patches, lr_patches) in enumerate(progress_bar):\n",
    "            hr_patches, lr_patches = hr_patches.to(device), lr_patches.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                outputs = model(lr_patches)\n",
    "                loss = criterion(outputs, hr_patches)\n",
    "                if torch.isnan(loss).any():\n",
    "                    print(\"Loss is NaN\")\n",
    "                    break\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_psnr += calculate_psnr(outputs, hr_patches).item()\n",
    "            outputs = outputs.float()\n",
    "            hr_patches = hr_patches.float()\n",
    "            running_ssim += ssim(outputs, hr_patches, data_range=1.0).item()\n",
    "\n",
    "            # Update the progress bar with the running loss\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        avg_train_psnr = running_psnr / len(train_loader)\n",
    "        avg_train_ssim = running_ssim / len(train_loader)\n",
    "        writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "        writer.add_scalar('PSNR/train', avg_train_psnr, epoch)\n",
    "        writer.add_scalar('SSIM/train', avg_train_ssim, epoch)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train PSNR: {avg_train_psnr:.4f}, Train SSIM: {avg_train_ssim:.4f}')\n",
    "    \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_psnr = 0.0\n",
    "        val_ssim = 0.0     \n",
    "        with torch.no_grad():\n",
    "            for hr_patches, lr_patches in val_loader:\n",
    "                hr_patches, lr_patches = hr_patches.to(device), lr_patches.to(device)\n",
    "                with autocast(enabled=True):\n",
    "                    outputs = model(lr_patches)\n",
    "                    loss = criterion(outputs, hr_patches)\n",
    "                    if torch.isnan(loss).any():\n",
    "                        print(\"Loss is NaN\")\n",
    "                        break\n",
    "                val_loss += loss.item()\n",
    "                val_psnr += calculate_psnr(outputs, hr_patches).item()\n",
    "                # Convert to float32 before calculating SSIM\n",
    "                outputs = outputs.float()\n",
    "                hr_patches = hr_patches.float()\n",
    "                val_ssim += ssim(outputs, hr_patches, data_range=1.0).item()\n",
    "    \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_psnr = val_psnr / len(val_loader)\n",
    "        avg_val_ssim = val_ssim / len(val_loader)\n",
    "        writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "        writer.add_scalar('PSNR/val', avg_val_psnr, epoch)\n",
    "        writer.add_scalar('SSIM/val', avg_val_ssim, epoch)\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}, Validation PSNR: {avg_val_psnr:.4f}, Validation SSIM: {avg_val_ssim:.4f}')\n",
    "\n",
    "        # Check early stopping condition\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "    \n",
    "    print('Training complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5352a190-3e19-4c4c-85a8-6b0a175e177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"UNet_Tukey_c-0.3_final.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca0e15-73da-45de-82eb-df904baf4979",
   "metadata": {},
   "source": [
    "### Training the model for SSIM + MAE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac127df6-9f49-4be0-9406-eab3a55508cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 07:38:50.728703: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-02 07:38:50.874078: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-02 07:38:51.596594: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-02 07:38:51.596666: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-02 07:38:51.596675: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Epoch 1/25: 100%|██████████| 2363/2363 [1:07:03<00:00,  1.70s/batch, loss=0.129] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train Loss: 0.0985, Train PSNR: 24.3744, Train SSIM: 0.7674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0856, Validation PSNR: 25.3044, Validation SSIM: 0.7966\n",
      "Validation loss decreased (inf --> 0.085587).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25: 100%|██████████| 2363/2363 [1:07:03<00:00,  1.70s/batch, loss=0.0927]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25], Train Loss: 0.0837, Train PSNR: 25.5299, Train SSIM: 0.7971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0807, Validation PSNR: 25.7845, Validation SSIM: 0.8023\n",
      "Validation loss decreased (0.085587 --> 0.080728).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25: 100%|██████████| 2363/2363 [1:07:02<00:00,  1.70s/batch, loss=0.105] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Train Loss: 0.0805, Train PSNR: 25.8157, Train SSIM: 0.8034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0794, Validation PSNR: 26.0624, Validation SSIM: 0.8055\n",
      "Validation loss decreased (0.080728 --> 0.079366).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25: 100%|██████████| 2363/2363 [1:07:03<00:00,  1.70s/batch, loss=0.0824]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25], Train Loss: 0.0792, Train PSNR: 25.9106, Train SSIM: 0.8062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0766, Validation PSNR: 26.2448, Validation SSIM: 0.8104\n",
      "Validation loss decreased (0.079366 --> 0.076637).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25: 100%|██████████| 2363/2363 [1:07:02<00:00,  1.70s/batch, loss=0.0441]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Train Loss: 0.0775, Train PSNR: 26.0461, Train SSIM: 0.8098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0772, Validation PSNR: 26.2642, Validation SSIM: 0.8098\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25: 100%|██████████| 2363/2363 [1:07:02<00:00,  1.70s/batch, loss=0.0362]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25], Train Loss: 0.0767, Train PSNR: 26.1087, Train SSIM: 0.8114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0758, Validation PSNR: 26.2083, Validation SSIM: 0.8130\n",
      "Validation loss decreased (0.076637 --> 0.075763).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25: 100%|██████████| 2363/2363 [1:07:02<00:00,  1.70s/batch, loss=0.0495]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Train Loss: 0.0760, Train PSNR: 26.1805, Train SSIM: 0.8129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0755, Validation PSNR: 26.3510, Validation SSIM: 0.8129\n",
      "Validation loss decreased (0.075763 --> 0.075503).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/25: 100%|██████████| 2363/2363 [1:07:02<00:00,  1.70s/batch, loss=0.0613]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25], Train Loss: 0.0755, Train PSNR: 26.2333, Train SSIM: 0.8141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0751, Validation PSNR: 26.3607, Validation SSIM: 0.8145\n",
      "Validation loss decreased (0.075503 --> 0.075054).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/25: 100%|██████████| 2363/2363 [1:07:02<00:00,  1.70s/batch, loss=0.2]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25], Train Loss: 0.0751, Train PSNR: 26.2753, Train SSIM: 0.8149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0757, Validation PSNR: 26.2728, Validation SSIM: 0.8156\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/25: 100%|██████████| 2363/2363 [1:07:02<00:00,  1.70s/batch, loss=0.129] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25], Train Loss: 0.0746, Train PSNR: 26.3246, Train SSIM: 0.8158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0739, Validation PSNR: 26.3606, Validation SSIM: 0.8173\n",
      "Validation loss decreased (0.075054 --> 0.073905).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25: 100%|██████████| 2363/2363 [1:07:03<00:00,  1.70s/batch, loss=0.101] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/25], Train Loss: 0.0743, Train PSNR: 26.3315, Train SSIM: 0.8167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0739, Validation PSNR: 26.3166, Validation SSIM: 0.8180\n",
      "Validation loss decreased (0.073905 --> 0.073875).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25: 100%|██████████| 2363/2363 [1:07:03<00:00,  1.70s/batch, loss=0.0677]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/25], Train Loss: 0.0739, Train PSNR: 26.3506, Train SSIM: 0.8175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0733, Validation PSNR: 26.4991, Validation SSIM: 0.8176\n",
      "Validation loss decreased (0.073875 --> 0.073291).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25: 100%|██████████| 2363/2363 [1:07:03<00:00,  1.70s/batch, loss=0.0588]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/25], Train Loss: 0.0736, Train PSNR: 26.3789, Train SSIM: 0.8181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0741, Validation PSNR: 26.3952, Validation SSIM: 0.8176\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/25: 100%|██████████| 2363/2363 [1:07:03<00:00,  1.70s/batch, loss=0.0969]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/25], Train Loss: 0.0733, Train PSNR: 26.3943, Train SSIM: 0.8189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0731, Validation PSNR: 26.5981, Validation SSIM: 0.8180\n",
      "Validation loss decreased (0.073291 --> 0.073068).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/25: 100%|██████████| 2363/2363 [1:07:02<00:00,  1.70s/batch, loss=0.101] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25], Train Loss: 0.0730, Train PSNR: 26.4522, Train SSIM: 0.8195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0737, Validation PSNR: 26.5020, Validation SSIM: 0.8168\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/25: 100%|██████████| 2363/2363 [1:07:02<00:00,  1.70s/batch, loss=0.0324]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/25], Train Loss: 0.0728, Train PSNR: 26.4072, Train SSIM: 0.8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0736, Validation PSNR: 26.4453, Validation SSIM: 0.8184\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/25: 100%|██████████| 2363/2363 [1:07:02<00:00,  1.70s/batch, loss=0.0512]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/25], Train Loss: 0.0725, Train PSNR: 26.4743, Train SSIM: 0.8207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0724, Validation PSNR: 26.5374, Validation SSIM: 0.8208\n",
      "Validation loss decreased (0.073068 --> 0.072357).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/25: 100%|██████████| 2363/2363 [1:07:02<00:00,  1.70s/batch, loss=0.0826]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/25], Train Loss: 0.0723, Train PSNR: 26.4904, Train SSIM: 0.8211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0741, Validation PSNR: 26.3242, Validation SSIM: 0.8197\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/25: 100%|██████████| 2363/2363 [1:07:02<00:00,  1.70s/batch, loss=0.0702]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/25], Train Loss: 0.0721, Train PSNR: 26.5160, Train SSIM: 0.8216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0722, Validation PSNR: 26.5913, Validation SSIM: 0.8206\n",
      "Validation loss decreased (0.072357 --> 0.072178).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/25:  76%|███████▌  | 1791/2363 [50:49<16:13,  1.70s/batch, loss=0.0776] "
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = UNetSRx4RiR(in_channels=3, out_channels=3, num_features=64, dropout_rate=0.0).to(device)\n",
    "    criterion = combined_ssim_l1_loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Initialize TensorBoard writer\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter('runs/UNetSRx4_ssim')\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "    \n",
    "    # Initialize learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    num_epochs = 25\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_psnr = 0.0\n",
    "        running_ssim = 0.0\n",
    "\n",
    "        # Wrap the train_loader with tqdm for progress bar\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        \n",
    "        for i, (hr_patches, lr_patches) in enumerate(progress_bar):\n",
    "            hr_patches, lr_patches = hr_patches.to(device), lr_patches.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast(enabled=False):\n",
    "                outputs = model(lr_patches)\n",
    "                loss = criterion(outputs, hr_patches)\n",
    "                if torch.isnan(loss).any():\n",
    "                    print(\"Loss is NaN\")\n",
    "                    break\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            # Apply gradient clipping\n",
    "            # nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_psnr += calculate_psnr(outputs, hr_patches).item()\n",
    "            outputs = outputs.float()\n",
    "            hr_patches = hr_patches.float()\n",
    "            running_ssim += ssim(outputs, hr_patches, data_range=1.0).item()\n",
    "\n",
    "            # Update the progress bar with the running loss\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        avg_train_psnr = running_psnr / len(train_loader)\n",
    "        avg_train_ssim = running_ssim / len(train_loader)\n",
    "        writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "        writer.add_scalar('PSNR/train', avg_train_psnr, epoch)\n",
    "        writer.add_scalar('SSIM/train', avg_train_ssim, epoch)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train PSNR: {avg_train_psnr:.4f}, Train SSIM: {avg_train_ssim:.4f}')\n",
    "    \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_psnr = 0.0\n",
    "        val_ssim = 0.0     \n",
    "        with torch.no_grad():\n",
    "            for hr_patches, lr_patches in val_loader:\n",
    "                hr_patches, lr_patches = hr_patches.to(device), lr_patches.to(device)\n",
    "                with autocast(enabled=False):\n",
    "                    outputs = model(lr_patches)\n",
    "                    loss = criterion(outputs, hr_patches)\n",
    "                    if torch.isnan(loss).any():\n",
    "                        print(\"Loss is NaN\")\n",
    "                        break\n",
    "                val_loss += loss.item()\n",
    "                val_psnr += calculate_psnr(outputs, hr_patches).item()\n",
    "                # Convert to float32 before calculating SSIM\n",
    "                outputs = outputs.float()\n",
    "                hr_patches = hr_patches.float()\n",
    "                val_ssim += ssim(outputs, hr_patches, data_range=1.0).item()\n",
    "    \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_psnr = val_psnr / len(val_loader)\n",
    "        avg_val_ssim = val_ssim / len(val_loader)\n",
    "        writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "        writer.add_scalar('PSNR/val', avg_val_psnr, epoch)\n",
    "        writer.add_scalar('SSIM/val', avg_val_ssim, epoch)\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}, Validation PSNR: {avg_val_psnr:.4f}, Validation SSIM: {avg_val_ssim:.4f}')\n",
    "\n",
    "        # Check early stopping condition\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "    \n",
    "    print('Training complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb388a-a01b-45a6-bfee-7f9c1dd67784",
   "metadata": {},
   "source": [
    "Continuing the training after epoch 19 as the session abrutly ended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c55ee144-e7b9-4e35-bbe1-93d068017f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 07:40:48.212839: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-03 07:40:48.351979: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-03 07:40:49.042439: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-03 07:40:49.042508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-03 07:40:49.042516: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Epoch 20/25: 100%|██████████| 2363/2363 [1:06:54<00:00,  1.70s/batch, loss=0.0706]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25], Train Loss: 0.0713, Train PSNR: 26.5379, Train SSIM: 0.8230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0721, Validation PSNR: 26.4905, Validation SSIM: 0.8205\n",
      "Validation loss decreased (inf --> 0.072086).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/25: 100%|██████████| 2363/2363 [1:06:03<00:00,  1.68s/batch, loss=0.079] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/25], Train Loss: 0.0711, Train PSNR: 26.5909, Train SSIM: 0.8236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0723, Validation PSNR: 26.4309, Validation SSIM: 0.8206\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/25: 100%|██████████| 2363/2363 [1:06:07<00:00,  1.68s/batch, loss=0.0449]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/25], Train Loss: 0.0708, Train PSNR: 26.6048, Train SSIM: 0.8242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0722, Validation PSNR: 26.5221, Validation SSIM: 0.8199\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/25: 100%|██████████| 2363/2363 [1:06:08<00:00,  1.68s/batch, loss=0.0326]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/25], Train Loss: 0.0708, Train PSNR: 26.5959, Train SSIM: 0.8243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0723, Validation PSNR: 26.4147, Validation SSIM: 0.8202\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 00004: reducing learning rate of group 0 to 2.5000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/25: 100%|██████████| 2363/2363 [1:06:12<00:00,  1.68s/batch, loss=0.109] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/25], Train Loss: 0.0702, Train PSNR: 26.7097, Train SSIM: 0.8256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0717, Validation PSNR: 26.5632, Validation SSIM: 0.8209\n",
      "Validation loss decreased (0.072086 --> 0.071669).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/25: 100%|██████████| 2363/2363 [1:06:12<00:00,  1.68s/batch, loss=0.0878]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25], Train Loss: 0.0700, Train PSNR: 26.6955, Train SSIM: 0.8260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0725, Validation PSNR: 26.2958, Validation SSIM: 0.8188\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Continuing the training after epoch 19 as the session abrutly ended\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = UNetSRx4RiR(in_channels=3, out_channels=3, num_features=64, dropout_rate=0.0).to(device)\n",
    "    criterion = combined_ssim_l1_loss\n",
    "    \n",
    "    # Load the model's state dict from the checkpoint\n",
    "    checkpoint = torch.load('checkpoint.pt')\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00005) # Reducing the loss function slightly\n",
    "    scaler = GradScaler()\n",
    "    start_epoch = 19  # Start from the next epoch\n",
    "    \n",
    "    # Initialize TensorBoard writer\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter('runs/UNetSRx4_ssim')\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "    \n",
    "    # Initialize learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    num_epochs = 25\n",
    "    for epoch in range(start_epoch, num_epochs): # Start from start_rpoch\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_psnr = 0.0\n",
    "        running_ssim = 0.0\n",
    "\n",
    "        # Wrap the train_loader with tqdm for progress bar\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        \n",
    "        for i, (hr_patches, lr_patches) in enumerate(progress_bar):\n",
    "            hr_patches, lr_patches = hr_patches.to(device), lr_patches.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast(enabled=False):\n",
    "                outputs = model(lr_patches)\n",
    "                loss = criterion(outputs, hr_patches)\n",
    "                if torch.isnan(loss).any():\n",
    "                    print(\"Loss is NaN\")\n",
    "                    break\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            # Apply gradient clipping\n",
    "            # nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_psnr += calculate_psnr(outputs, hr_patches).item()\n",
    "            outputs = outputs.float()\n",
    "            hr_patches = hr_patches.float()\n",
    "            running_ssim += ssim(outputs, hr_patches, data_range=1.0).item()\n",
    "\n",
    "            # Update the progress bar with the running loss\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        avg_train_psnr = running_psnr / len(train_loader)\n",
    "        avg_train_ssim = running_ssim / len(train_loader)\n",
    "        writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "        writer.add_scalar('PSNR/train', avg_train_psnr, epoch)\n",
    "        writer.add_scalar('SSIM/train', avg_train_ssim, epoch)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train PSNR: {avg_train_psnr:.4f}, Train SSIM: {avg_train_ssim:.4f}')\n",
    "    \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_psnr = 0.0\n",
    "        val_ssim = 0.0     \n",
    "        with torch.no_grad():\n",
    "            for hr_patches, lr_patches in val_loader:\n",
    "                hr_patches, lr_patches = hr_patches.to(device), lr_patches.to(device)\n",
    "                with autocast(enabled=False):\n",
    "                    outputs = model(lr_patches)\n",
    "                    loss = criterion(outputs, hr_patches)\n",
    "                    if torch.isnan(loss).any():\n",
    "                        print(\"Loss is NaN\")\n",
    "                        break\n",
    "                val_loss += loss.item()\n",
    "                val_psnr += calculate_psnr(outputs, hr_patches).item()\n",
    "                # Convert to float32 before calculating SSIM\n",
    "                outputs = outputs.float()\n",
    "                hr_patches = hr_patches.float()\n",
    "                val_ssim += ssim(outputs, hr_patches, data_range=1.0).item()\n",
    "    \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_psnr = val_psnr / len(val_loader)\n",
    "        avg_val_ssim = val_ssim / len(val_loader)\n",
    "        writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "        writer.add_scalar('PSNR/val', avg_val_psnr, epoch)\n",
    "        writer.add_scalar('SSIM/val', avg_val_ssim, epoch)\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}, Validation PSNR: {avg_val_psnr:.4f}, Validation SSIM: {avg_val_ssim:.4f}')\n",
    "\n",
    "        # Check early stopping condition\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "    \n",
    "    print('Training complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75b32790-c51e-44a7-a874-0718da61be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"UNet_l1_ssim_final.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a82591-775b-401c-b34c-cb14d1505fdf",
   "metadata": {},
   "source": [
    "### Training the model for Charbonnier loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a255c6a-dc7c-4e99-9332-9a93cc359cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 04:24:43.462607: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-04 04:24:43.603426: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-04 04:24:44.318968: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-04 04:24:44.319057: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-04 04:24:44.319066: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Epoch 1/25: 100%|██████████| 1182/1182 [23:26<00:00,  1.19s/batch, loss=0.0349]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train Loss: 0.0455, Train PSNR: 23.6736, Train SSIM: 0.7262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0327, Validation PSNR: 25.4157, Validation SSIM: 0.7709\n",
      "Validation loss decreased (inf --> 0.032664).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25: 100%|██████████| 1182/1182 [23:26<00:00,  1.19s/batch, loss=0.0362]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25], Train Loss: 0.0338, Train PSNR: 25.2284, Train SSIM: 0.7751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0334, Validation PSNR: 25.4563, Validation SSIM: 0.7848\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25: 100%|██████████| 1182/1182 [23:27<00:00,  1.19s/batch, loss=0.0424]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Train Loss: 0.0316, Train PSNR: 25.5467, Train SSIM: 0.7848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0320, Validation PSNR: 25.6961, Validation SSIM: 0.7841\n",
      "Validation loss decreased (0.032664 --> 0.032025).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25: 100%|██████████| 1182/1182 [23:27<00:00,  1.19s/batch, loss=0.0171]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25], Train Loss: 0.0305, Train PSNR: 25.6753, Train SSIM: 0.7899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0281, Validation PSNR: 26.1552, Validation SSIM: 0.7945\n",
      "Validation loss decreased (0.032025 --> 0.028102).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25: 100%|██████████| 1182/1182 [23:27<00:00,  1.19s/batch, loss=0.0243]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Train Loss: 0.0298, Train PSNR: 25.8089, Train SSIM: 0.7933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0279, Validation PSNR: 26.1927, Validation SSIM: 0.7957\n",
      "Validation loss decreased (0.028102 --> 0.027871).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25: 100%|██████████| 1182/1182 [23:29<00:00,  1.19s/batch, loss=0.0267]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25], Train Loss: 0.0292, Train PSNR: 25.8740, Train SSIM: 0.7957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0297, Validation PSNR: 26.0723, Validation SSIM: 0.7992\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25: 100%|██████████| 1182/1182 [23:29<00:00,  1.19s/batch, loss=0.0663]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Train Loss: 0.0288, Train PSNR: 25.9514, Train SSIM: 0.7981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0277, Validation PSNR: 26.2551, Validation SSIM: 0.7996\n",
      "Validation loss decreased (0.027871 --> 0.027697).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/25: 100%|██████████| 1182/1182 [23:27<00:00,  1.19s/batch, loss=0.0256]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25], Train Loss: 0.0283, Train PSNR: 26.0037, Train SSIM: 0.8003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0271, Validation PSNR: 26.3387, Validation SSIM: 0.7997\n",
      "Validation loss decreased (0.027697 --> 0.027074).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/25: 100%|██████████| 1182/1182 [23:27<00:00,  1.19s/batch, loss=0.0397]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25], Train Loss: 0.0281, Train PSNR: 26.0428, Train SSIM: 0.8017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0282, Validation PSNR: 26.1520, Validation SSIM: 0.7997\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/25: 100%|██████████| 1182/1182 [23:27<00:00,  1.19s/batch, loss=0.0478]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25], Train Loss: 0.0278, Train PSNR: 26.1011, Train SSIM: 0.8033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0269, Validation PSNR: 26.2393, Validation SSIM: 0.8031\n",
      "Validation loss decreased (0.027074 --> 0.026872).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25: 100%|██████████| 1182/1182 [23:28<00:00,  1.19s/batch, loss=0.0316]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/25], Train Loss: 0.0276, Train PSNR: 26.1277, Train SSIM: 0.8041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0265, Validation PSNR: 26.4285, Validation SSIM: 0.8055\n",
      "Validation loss decreased (0.026872 --> 0.026546).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25: 100%|██████████| 1182/1182 [23:28<00:00,  1.19s/batch, loss=0.0177]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/25], Train Loss: 0.0272, Train PSNR: 26.1828, Train SSIM: 0.8057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0267, Validation PSNR: 26.3562, Validation SSIM: 0.8048\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25: 100%|██████████| 1182/1182 [23:26<00:00,  1.19s/batch, loss=0.0361]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/25], Train Loss: 0.0271, Train PSNR: 26.2104, Train SSIM: 0.8064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0272, Validation PSNR: 26.0432, Validation SSIM: 0.8039\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/25: 100%|██████████| 1182/1182 [23:25<00:00,  1.19s/batch, loss=0.0289]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/25], Train Loss: 0.0268, Train PSNR: 26.2478, Train SSIM: 0.8073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0278, Validation PSNR: 26.2759, Validation SSIM: 0.8047\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 00014: reducing learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/25: 100%|██████████| 1182/1182 [23:28<00:00,  1.19s/batch, loss=0.0304]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25], Train Loss: 0.0261, Train PSNR: 26.3472, Train SSIM: 0.8100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0255, Validation PSNR: 26.5442, Validation SSIM: 0.8080\n",
      "Validation loss decreased (0.026546 --> 0.025503).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/25: 100%|██████████| 1182/1182 [23:31<00:00,  1.19s/batch, loss=0.0365]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/25], Train Loss: 0.0260, Train PSNR: 26.3464, Train SSIM: 0.8107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0254, Validation PSNR: 26.3714, Validation SSIM: 0.8083\n",
      "Validation loss decreased (0.025503 --> 0.025384).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/25:  57%|█████▋    | 678/1182 [13:29<10:02,  1.19s/batch, loss=0.0228]"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = UNetSRx4RiR(in_channels=3, out_channels=3, num_features=64, dropout_rate=0.0).to(device)\n",
    "    criterion = CharbonnierLoss(epsilon=1e-4)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Initialize TensorBoard writer\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter('runs/UNetSRx4_charbonnier')\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "    \n",
    "    # Initialize learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    num_epochs = 25\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_psnr = 0.0\n",
    "        running_ssim = 0.0\n",
    "\n",
    "        # Wrap the train_loader with tqdm for progress bar\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        \n",
    "        for i, (hr_patches, lr_patches) in enumerate(progress_bar):\n",
    "            hr_patches, lr_patches = hr_patches.to(device), lr_patches.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast(enabled=True):\n",
    "                outputs = model(lr_patches)\n",
    "                loss = criterion(outputs, hr_patches)\n",
    "                if torch.isnan(loss).any():\n",
    "                    print(\"Loss is NaN\")\n",
    "                    break\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            # Apply gradient clipping\n",
    "            # nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_psnr += calculate_psnr(outputs, hr_patches).item()\n",
    "            outputs = outputs.float()\n",
    "            hr_patches = hr_patches.float()\n",
    "            running_ssim += ssim(outputs, hr_patches, data_range=1.0).item()\n",
    "\n",
    "            # Update the progress bar with the running loss\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        avg_train_psnr = running_psnr / len(train_loader)\n",
    "        avg_train_ssim = running_ssim / len(train_loader)\n",
    "        writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "        writer.add_scalar('PSNR/train', avg_train_psnr, epoch)\n",
    "        writer.add_scalar('SSIM/train', avg_train_ssim, epoch)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train PSNR: {avg_train_psnr:.4f}, Train SSIM: {avg_train_ssim:.4f}')\n",
    "    \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_psnr = 0.0\n",
    "        val_ssim = 0.0     \n",
    "        with torch.no_grad():\n",
    "            for hr_patches, lr_patches in val_loader:\n",
    "                hr_patches, lr_patches = hr_patches.to(device), lr_patches.to(device)\n",
    "                with autocast(enabled=True):\n",
    "                    outputs = model(lr_patches)\n",
    "                    loss = criterion(outputs, hr_patches)\n",
    "                    if torch.isnan(loss).any():\n",
    "                        print(\"Loss is NaN\")\n",
    "                        break\n",
    "                val_loss += loss.item()\n",
    "                val_psnr += calculate_psnr(outputs, hr_patches).item()\n",
    "                # Convert to float32 before calculating SSIM\n",
    "                outputs = outputs.float()\n",
    "                hr_patches = hr_patches.float()\n",
    "                val_ssim += ssim(outputs, hr_patches, data_range=1.0).item()\n",
    "    \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_psnr = val_psnr / len(val_loader)\n",
    "        avg_val_ssim = val_ssim / len(val_loader)\n",
    "        writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "        writer.add_scalar('PSNR/val', avg_val_psnr, epoch)\n",
    "        writer.add_scalar('SSIM/val', avg_val_ssim, epoch)\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}, Validation PSNR: {avg_val_psnr:.4f}, Validation SSIM: {avg_val_ssim:.4f}')\n",
    "\n",
    "        # Check early stopping condition\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "    \n",
    "    print('Training complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca01ec-4bbc-4dce-83d7-52eb0093e997",
   "metadata": {},
   "source": [
    "Continuing the training after epoch 16 as the session abrutly ended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58f4b772-e24e-4b10-a5fb-f08fda4c4dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 15:36:39.383257: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-04 15:36:49.704962: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-04 15:37:36.680281: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-04 15:37:36.680679: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-04 15:37:36.680689: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Epoch 17/25: 100%|██████████| 1182/1182 [26:19<00:00,  1.34s/batch, loss=0.0178] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/25], Train Loss: 0.0256, Train PSNR: 26.4188, Train SSIM: 0.8120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0254, Validation PSNR: 26.5091, Validation SSIM: 0.8177\n",
      "Validation loss decreased (inf --> 0.025369).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/25: 100%|██████████| 1182/1182 [23:10<00:00,  1.18s/batch, loss=0.0415]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/25], Train Loss: 0.0256, Train PSNR: 26.4330, Train SSIM: 0.8123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0253, Validation PSNR: 26.4657, Validation SSIM: 0.8169\n",
      "Validation loss decreased (0.025369 --> 0.025327).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/25: 100%|██████████| 1182/1182 [23:11<00:00,  1.18s/batch, loss=0.0335]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/25], Train Loss: 0.0255, Train PSNR: 26.4339, Train SSIM: 0.8128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0251, Validation PSNR: 26.4881, Validation SSIM: 0.8174\n",
      "Validation loss decreased (0.025327 --> 0.025119).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/25: 100%|██████████| 1182/1182 [23:11<00:00,  1.18s/batch, loss=0.0279]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25], Train Loss: 0.0255, Train PSNR: 26.4537, Train SSIM: 0.8123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0257, Validation PSNR: 26.2949, Validation SSIM: 0.8145\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/25: 100%|██████████| 1182/1182 [23:11<00:00,  1.18s/batch, loss=0.0277]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/25], Train Loss: 0.0255, Train PSNR: 26.4522, Train SSIM: 0.8134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0250, Validation PSNR: 26.5333, Validation SSIM: 0.8184\n",
      "Validation loss decreased (0.025119 --> 0.025020).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/25: 100%|██████████| 1182/1182 [23:12<00:00,  1.18s/batch, loss=0.02]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/25], Train Loss: 0.0253, Train PSNR: 26.4974, Train SSIM: 0.8141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0254, Validation PSNR: 26.4749, Validation SSIM: 0.8172\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/25: 100%|██████████| 1182/1182 [23:11<00:00,  1.18s/batch, loss=0.0215]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/25], Train Loss: 0.0253, Train PSNR: 26.4909, Train SSIM: 0.8143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0255, Validation PSNR: 26.3423, Validation SSIM: 0.8159\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/25: 100%|██████████| 1182/1182 [23:11<00:00,  1.18s/batch, loss=0.0328]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/25], Train Loss: 0.0252, Train PSNR: 26.4916, Train SSIM: 0.8146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0249, Validation PSNR: 26.5465, Validation SSIM: 0.8187\n",
      "Validation loss decreased (0.025020 --> 0.024882).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/25: 100%|██████████| 1182/1182 [23:11<00:00,  1.18s/batch, loss=0.0185]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25], Train Loss: 0.0252, Train PSNR: 26.5254, Train SSIM: 0.8150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0256, Validation PSNR: 26.3645, Validation SSIM: 0.8166\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Continuing the training after epoch 16 as the session abrutly ended\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = UNetSRx4RiR(in_channels=3, out_channels=3, num_features=64, dropout_rate=0.0).to(device)\n",
    "    criterion = CharbonnierLoss(epsilon=1e-4)\n",
    "    \n",
    "    # Load the model's state dict from the checkpoint\n",
    "    checkpoint = torch.load('checkpoint.pt')\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00005) # Reducing the loss function slightly\n",
    "    scaler = GradScaler()\n",
    "    start_epoch = 16  # Start from the next epoch\n",
    "    \n",
    "    # Initialize TensorBoard writer\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter('runs/UNetSRx4_charbonnier')\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "    \n",
    "    # Initialize learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    num_epochs = 25\n",
    "    for epoch in range(start_epoch, num_epochs): # Start from start_rpoch\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_psnr = 0.0\n",
    "        running_ssim = 0.0\n",
    "\n",
    "        # Wrap the train_loader with tqdm for progress bar\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        \n",
    "        for i, (hr_patches, lr_patches) in enumerate(progress_bar):\n",
    "            hr_patches, lr_patches = hr_patches.to(device), lr_patches.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast(enabled=True):\n",
    "                outputs = model(lr_patches)\n",
    "                loss = criterion(outputs, hr_patches)\n",
    "                if torch.isnan(loss).any():\n",
    "                    print(\"Loss is NaN\")\n",
    "                    break\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            # Apply gradient clipping\n",
    "            # nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_psnr += calculate_psnr(outputs, hr_patches).item()\n",
    "            outputs = outputs.float()\n",
    "            hr_patches = hr_patches.float()\n",
    "            running_ssim += ssim(outputs, hr_patches, data_range=1.0).item()\n",
    "\n",
    "            # Update the progress bar with the running loss\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        avg_train_psnr = running_psnr / len(train_loader)\n",
    "        avg_train_ssim = running_ssim / len(train_loader)\n",
    "        writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "        writer.add_scalar('PSNR/train', avg_train_psnr, epoch)\n",
    "        writer.add_scalar('SSIM/train', avg_train_ssim, epoch)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train PSNR: {avg_train_psnr:.4f}, Train SSIM: {avg_train_ssim:.4f}')\n",
    "    \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_psnr = 0.0\n",
    "        val_ssim = 0.0     \n",
    "        with torch.no_grad():\n",
    "            for hr_patches, lr_patches in val_loader:\n",
    "                hr_patches, lr_patches = hr_patches.to(device), lr_patches.to(device)\n",
    "                with autocast(enabled=True):\n",
    "                    outputs = model(lr_patches)\n",
    "                    loss = criterion(outputs, hr_patches)\n",
    "                    if torch.isnan(loss).any():\n",
    "                        print(\"Loss is NaN\")\n",
    "                        break\n",
    "                val_loss += loss.item()\n",
    "                val_psnr += calculate_psnr(outputs, hr_patches).item()\n",
    "                # Convert to float32 before calculating SSIM\n",
    "                outputs = outputs.float()\n",
    "                hr_patches = hr_patches.float()\n",
    "                val_ssim += ssim(outputs, hr_patches, data_range=1.0).item()\n",
    "    \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_psnr = val_psnr / len(val_loader)\n",
    "        avg_val_ssim = val_ssim / len(val_loader)\n",
    "        writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "        writer.add_scalar('PSNR/val', avg_val_psnr, epoch)\n",
    "        writer.add_scalar('SSIM/val', avg_val_ssim, epoch)\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}, Validation PSNR: {avg_val_psnr:.4f}, Validation SSIM: {avg_val_ssim:.4f}')\n",
    "\n",
    "        # Check early stopping condition\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "    \n",
    "    print('Training complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afb2d349-c3aa-439c-9f67-3c5ffd90ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"UNet_charbonnier_eps1e-4_final.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3cf56f-8cd6-4f86-9f3e-e39f768d66f9",
   "metadata": {},
   "source": [
    "### Training the model for TV + MAE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c56e2cc2-84a5-4449-b988-754e7e0af109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 12:18:04.038916: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-06 12:18:17.010591: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-06 12:19:00.370499: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-06 12:19:00.370912: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-06 12:19:00.370922: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Epoch 1/25: 100%|██████████| 1182/1182 [26:56<00:00,  1.37s/batch, loss=0.0405]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train Loss: 0.0469, Train PSNR: 23.4509, Train SSIM: 0.7100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0376, Validation PSNR: 24.7016, Validation SSIM: 0.7602\n",
      "Validation loss decreased (inf --> 0.037649).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25: 100%|██████████| 1182/1182 [23:48<00:00,  1.21s/batch, loss=0.0429]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25], Train Loss: 0.0353, Train PSNR: 24.9652, Train SSIM: 0.7632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0322, Validation PSNR: 25.4593, Validation SSIM: 0.7760\n",
      "Validation loss decreased (0.037649 --> 0.032246).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25: 100%|██████████| 1182/1182 [23:51<00:00,  1.21s/batch, loss=0.0399]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Train Loss: 0.0325, Train PSNR: 25.3697, Train SSIM: 0.7758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0303, Validation PSNR: 25.7446, Validation SSIM: 0.7854\n",
      "Validation loss decreased (0.032246 --> 0.030276).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25: 100%|██████████| 1182/1182 [23:50<00:00,  1.21s/batch, loss=0.0421]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25], Train Loss: 0.0311, Train PSNR: 25.5657, Train SSIM: 0.7826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0297, Validation PSNR: 25.8333, Validation SSIM: 0.7908\n",
      "Validation loss decreased (0.030276 --> 0.029730).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25: 100%|██████████| 1182/1182 [23:48<00:00,  1.21s/batch, loss=0.0197]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Train Loss: 0.0303, Train PSNR: 25.6908, Train SSIM: 0.7878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0283, Validation PSNR: 26.0205, Validation SSIM: 0.7936\n",
      "Validation loss decreased (0.029730 --> 0.028310).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25: 100%|██████████| 1182/1182 [23:49<00:00,  1.21s/batch, loss=0.0501]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25], Train Loss: 0.0295, Train PSNR: 25.7955, Train SSIM: 0.7912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0282, Validation PSNR: 26.0504, Validation SSIM: 0.7972\n",
      "Validation loss decreased (0.028310 --> 0.028214).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25: 100%|██████████| 1182/1182 [23:48<00:00,  1.21s/batch, loss=0.0365]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Train Loss: 0.0289, Train PSNR: 25.8855, Train SSIM: 0.7942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0280, Validation PSNR: 26.1129, Validation SSIM: 0.7988\n",
      "Validation loss decreased (0.028214 --> 0.028016).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/25: 100%|██████████| 1182/1182 [23:47<00:00,  1.21s/batch, loss=0.0224]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25], Train Loss: 0.0287, Train PSNR: 25.9381, Train SSIM: 0.7959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0274, Validation PSNR: 26.1736, Validation SSIM: 0.7982\n",
      "Validation loss decreased (0.028016 --> 0.027355).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/25: 100%|██████████| 1182/1182 [23:46<00:00,  1.21s/batch, loss=0.0295]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25], Train Loss: 0.0282, Train PSNR: 25.9896, Train SSIM: 0.7980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0278, Validation PSNR: 26.1704, Validation SSIM: 0.7992\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/25: 100%|██████████| 1182/1182 [23:46<00:00,  1.21s/batch, loss=0.0185]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25], Train Loss: 0.0280, Train PSNR: 26.0230, Train SSIM: 0.7996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0274, Validation PSNR: 26.1925, Validation SSIM: 0.7993\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25: 100%|██████████| 1182/1182 [23:45<00:00,  1.21s/batch, loss=0.0383]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/25], Train Loss: 0.0278, Train PSNR: 26.0902, Train SSIM: 0.8006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0266, Validation PSNR: 26.2838, Validation SSIM: 0.8039\n",
      "Validation loss decreased (0.027355 --> 0.026636).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25: 100%|██████████| 1182/1182 [23:44<00:00,  1.21s/batch, loss=0.0418]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/25], Train Loss: 0.0275, Train PSNR: 26.1054, Train SSIM: 0.8021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0270, Validation PSNR: 26.2725, Validation SSIM: 0.8045\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25: 100%|██████████| 1182/1182 [23:44<00:00,  1.20s/batch, loss=0.0435]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/25], Train Loss: 0.0273, Train PSNR: 26.1504, Train SSIM: 0.8031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0318, Validation PSNR: 25.2761, Validation SSIM: 0.7928\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/25: 100%|██████████| 1182/1182 [23:43<00:00,  1.20s/batch, loss=0.0249]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/25], Train Loss: 0.0271, Train PSNR: 26.1726, Train SSIM: 0.8039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0271, Validation PSNR: 26.2755, Validation SSIM: 0.8033\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 00014: reducing learning rate of group 0 to 2.5000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/25: 100%|██████████| 1182/1182 [23:45<00:00,  1.21s/batch, loss=0.0434]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25], Train Loss: 0.0263, Train PSNR: 26.2761, Train SSIM: 0.8069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0258, Validation PSNR: 26.3978, Validation SSIM: 0.8074\n",
      "Validation loss decreased (0.026636 --> 0.025815).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/25: 100%|██████████| 1182/1182 [23:44<00:00,  1.21s/batch, loss=0.022] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/25], Train Loss: 0.0261, Train PSNR: 26.3118, Train SSIM: 0.8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0255, Validation PSNR: 26.4300, Validation SSIM: 0.8087\n",
      "Validation loss decreased (0.025815 --> 0.025523).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/25: 100%|██████████| 1182/1182 [23:43<00:00,  1.20s/batch, loss=0.0345]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/25], Train Loss: 0.0261, Train PSNR: 26.3207, Train SSIM: 0.8084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0259, Validation PSNR: 26.4123, Validation SSIM: 0.8066\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/25: 100%|██████████| 1182/1182 [23:43<00:00,  1.20s/batch, loss=0.03]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/25], Train Loss: 0.0260, Train PSNR: 26.3400, Train SSIM: 0.8089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0254, Validation PSNR: 26.4487, Validation SSIM: 0.8091\n",
      "Validation loss decreased (0.025523 --> 0.025404).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/25: 100%|██████████| 1182/1182 [23:43<00:00,  1.20s/batch, loss=0.0257]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/25], Train Loss: 0.0259, Train PSNR: 26.3579, Train SSIM: 0.8096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0257, Validation PSNR: 26.4356, Validation SSIM: 0.8096\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/25: 100%|██████████| 1182/1182 [23:44<00:00,  1.21s/batch, loss=0.0343]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25], Train Loss: 0.0259, Train PSNR: 26.3747, Train SSIM: 0.8099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0255, Validation PSNR: 26.4686, Validation SSIM: 0.8098\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/25: 100%|██████████| 1182/1182 [23:42<00:00,  1.20s/batch, loss=0.0254]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/25], Train Loss: 0.0258, Train PSNR: 26.4058, Train SSIM: 0.8105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0255, Validation PSNR: 26.4624, Validation SSIM: 0.8109\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 00021: reducing learning rate of group 0 to 1.2500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/25: 100%|██████████| 1182/1182 [23:43<00:00,  1.20s/batch, loss=0.0292]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/25], Train Loss: 0.0254, Train PSNR: 26.4531, Train SSIM: 0.8118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0254, Validation PSNR: 26.4769, Validation SSIM: 0.8112\n",
      "Validation loss decreased (0.025404 --> 0.025362).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/25: 100%|██████████| 1182/1182 [23:43<00:00,  1.20s/batch, loss=0.0201]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/25], Train Loss: 0.0254, Train PSNR: 26.4558, Train SSIM: 0.8122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0252, Validation PSNR: 26.4951, Validation SSIM: 0.8110\n",
      "Validation loss decreased (0.025362 --> 0.025232).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/25: 100%|██████████| 1182/1182 [23:44<00:00,  1.20s/batch, loss=0.0438]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/25], Train Loss: 0.0253, Train PSNR: 26.4742, Train SSIM: 0.8126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0254, Validation PSNR: 26.4898, Validation SSIM: 0.8113\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/25: 100%|██████████| 1182/1182 [23:44<00:00,  1.21s/batch, loss=0.0176]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25], Train Loss: 0.0253, Train PSNR: 26.5016, Train SSIM: 0.8130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0252, Validation PSNR: 26.5008, Validation SSIM: 0.8117\n",
      "Validation loss decreased (0.025232 --> 0.025196).  Saving model ...\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = UNetSRx4RiR(in_channels=3, out_channels=3, num_features=64, dropout_rate=0.0).to(device)\n",
    "    l1_loss = nn.L1Loss()\n",
    "    tv_loss = TVLoss(tv_weight=1e-4)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Initialize TensorBoard writer\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter('runs/UNetSRx4_tv-1e-4_mae_final')\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "    \n",
    "    # Initialize learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    num_epochs = 25\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_psnr = 0.0\n",
    "        running_ssim = 0.0\n",
    "\n",
    "        # Wrap the train_loader with tqdm for progress bar\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        \n",
    "        for i, (hr_patches, lr_patches) in enumerate(progress_bar):\n",
    "            hr_patches, lr_patches = hr_patches.to(device), lr_patches.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast(enabled=True):\n",
    "                outputs = model(lr_patches)\n",
    "                loss = combined_tv_mae_loss(outputs, hr_patches)\n",
    "                if torch.isnan(loss).any():\n",
    "                    print(\"Loss is NaN\")\n",
    "                    continue\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            # Apply gradient clipping\n",
    "            # nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_psnr += calculate_psnr(outputs, hr_patches).item()\n",
    "            outputs = outputs.float()\n",
    "            hr_patches = hr_patches.float()\n",
    "            running_ssim += ssim(outputs, hr_patches, data_range=1.0).item()\n",
    "\n",
    "            # Update the progress bar with the running loss\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        avg_train_psnr = running_psnr / len(train_loader)\n",
    "        avg_train_ssim = running_ssim / len(train_loader)\n",
    "        writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "        writer.add_scalar('PSNR/train', avg_train_psnr, epoch)\n",
    "        writer.add_scalar('SSIM/train', avg_train_ssim, epoch)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train PSNR: {avg_train_psnr:.4f}, Train SSIM: {avg_train_ssim:.4f}')\n",
    "    \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_psnr = 0.0\n",
    "        val_ssim = 0.0     \n",
    "        with torch.no_grad():\n",
    "            for hr_patches, lr_patches in val_loader:\n",
    "                hr_patches, lr_patches = hr_patches.to(device), lr_patches.to(device)\n",
    "                with autocast(enabled=True):\n",
    "                    outputs = model(lr_patches)\n",
    "                    loss = combined_tv_mae_loss(outputs, hr_patches)\n",
    "                    if torch.isnan(loss).any():\n",
    "                        print(\"Loss is NaN\")\n",
    "                        continue\n",
    "                val_loss += loss.item()\n",
    "                val_psnr += calculate_psnr(outputs, hr_patches).item()\n",
    "                # Convert to float32 before calculating SSIM\n",
    "                outputs = outputs.float()\n",
    "                hr_patches = hr_patches.float()\n",
    "                val_ssim += ssim(outputs, hr_patches, data_range=1.0).item()\n",
    "    \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_psnr = val_psnr / len(val_loader)\n",
    "        avg_val_ssim = val_ssim / len(val_loader)\n",
    "        writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "        writer.add_scalar('PSNR/val', avg_val_psnr, epoch)\n",
    "        writer.add_scalar('SSIM/val', avg_val_ssim, epoch)\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}, Validation PSNR: {avg_val_psnr:.4f}, Validation SSIM: {avg_val_ssim:.4f}')\n",
    "\n",
    "        # Check early stopping condition\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "    \n",
    "    print('Training complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fc4c109-a4cd-47fb-bded-3b11c9965601",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"UNet_1e-4tv_mae_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e75cb-7422-49f2-8d00-b5e398013f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
